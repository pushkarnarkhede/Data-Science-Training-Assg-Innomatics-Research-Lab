{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e5542e4-3c0d-4fac-8f27-c8012c549d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "899e66eb-de4a-4f1c-9684-15782fe4d826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec9fed03-4710-4953-a626-91e9ae98cdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import boston_housing  # importing inbuilt dataset\n",
    "from tensorflow.keras.models import Sequential  # sequential model \n",
    "from keras.layers import BatchNormalization, Dense  # for creating fully connected NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de2ec3c2-9681-49bd-a1c9-2809de93949b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((506, 13), (506,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(feature,price),_ = boston_housing.load_data(test_split=0)   # to load whole data i have make test split as 0\n",
    "feature.shape , price.shape  # checking the shape of data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62cd907-4bb4-4e06-97b9-a2a34955d14f",
   "metadata": {},
   "source": [
    "## Perceptron NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0647d2c3-e911-47e1-9603-be015da78c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape = (13,)))  #we have 13 feature hence input layer with 13 neuron and no hidden layer\n",
    "model.add(Dense(1))  # op layer with only 1 neuron becuase it is regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b0b105a-32c1-4345-9669-93235aa92daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_5 (Batch (None, 13)                52        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 14        \n",
      "=================================================================\n",
      "Total params: 66\n",
      "Trainable params: 40\n",
      "Non-trainable params: 26\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()  # to get the summary of our model which shows how many parametrs our model have and structure of NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ed5163f-e538-44ff-abdf-b0f3334895b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 35ms/step - loss: 34.0115 - val_loss: 33.9920\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 29.2164 - val_loss: 47.0208\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1333 - val_loss: 146.5575\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 43.2883 - val_loss: 35.6240\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 27.5063 - val_loss: 60.2390\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 36.0836 - val_loss: 44.5561\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 30.7369 - val_loss: 31.3289\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 40.90 - 0s 3ms/step - loss: 32.7912 - val_loss: 25.3508\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 30.8089 - val_loss: 41.4795\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.2455 - val_loss: 65.4084\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 29.2980 - val_loss: 46.2602\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 30.9436 - val_loss: 28.0947\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 29.3861 - val_loss: 49.1469\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 28.0379 - val_loss: 89.2991\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 34.5246 - val_loss: 28.7252\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 28.8974 - val_loss: 30.5676\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 29.6791 - val_loss: 47.4126\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 34.1264 - val_loss: 25.1202\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 30.9890 - val_loss: 75.6869\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.6650 - val_loss: 27.8138\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - ETA: 0s - loss: 30.35 - 0s 3ms/step - loss: 30.7692 - val_loss: 25.2485\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 29.5512 - val_loss: 28.9808\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 29.3596 - val_loss: 44.6853\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 31.4341 - val_loss: 65.1025\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.9108 - val_loss: 41.1710\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 35.2927 - val_loss: 413.5154\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 71.7729 - val_loss: 184.6032\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 41.3415 - val_loss: 25.6003\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 26.8030 - val_loss: 65.3520\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 29.0599 - val_loss: 59.5169\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 29.3447 - val_loss: 29.9538\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 29.0049 - val_loss: 36.2619\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 27.7157 - val_loss: 73.0510\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.0043 - val_loss: 57.4341\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 31.9638 - val_loss: 25.2470\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 28.6477 - val_loss: 54.5093\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 27.3674 - val_loss: 28.7976\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.9527 - val_loss: 35.0656\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 27.8512 - val_loss: 24.1534\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 28.7078 - val_loss: 51.2751\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 31.0990 - val_loss: 98.6853\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 36.7739 - val_loss: 50.9066\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 31.5521 - val_loss: 652.3410\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 121.0080 - val_loss: 54.9072\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 34.4453 - val_loss: 57.3216\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2667 - val_loss: 25.1478\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.2174 - val_loss: 57.2401\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.9212 - val_loss: 31.6793\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 27.8067 - val_loss: 35.9597\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1869 - val_loss: 47.6503\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a886a1550>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss='mse')  # optimiser stocastics gradient descent  loss is mean square error due to regression problem\n",
    "model.fit(feature,price,epochs=50,validation_split=0.3) # val_split = 0.3 means 30% of data from feature,price are used as validation data\n",
    "# epoch = 50 and as we have choosen optimizer is SGD hence there will 50 forward and backword propagation happens to updates weights and train NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38c7622-e4c9-4858-9b7a-e80eac838853",
   "metadata": {},
   "source": [
    "- as we have used SGD optimizer with default paramaters i.e learning rate and momentun hence the loss is varing.\n",
    "- we will check how our loss is varing if we change the learning rate and momentun."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd1a7ba-893a-4387-9760-c9318e56141d",
   "metadata": {},
   "source": [
    "## Perceptron NN with Modified Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "146cdf88-0678-4a86-b200-2fda4a249415",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4535e40-83bb-4ac2-beff-b15aaee94022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 235.2409 - val_loss: 332.1584\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 132.1256 - val_loss: 56.9486\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 64.0832 - val_loss: 142.7607\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 41.1371 - val_loss: 24.3836\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 44.7526 - val_loss: 79.1605\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 35.2376 - val_loss: 112.4828\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 41.8944 - val_loss: 61.2045\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 47.5577 - val_loss: 52.3019\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 39.2833 - val_loss: 81.1048\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 55.9011 - val_loss: 39.7269\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 50.5539 - val_loss: 35.2393\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 36.8228 - val_loss: 31.4904\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 40.6266 - val_loss: 35.0715\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 42.4711 - val_loss: 49.3879\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 40.5399 - val_loss: 38.6113\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.3958 - val_loss: 38.0864\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 34.3954 - val_loss: 36.4013\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 48.3571 - val_loss: 73.9424\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 44.5080 - val_loss: 136.2820\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 111.8304 - val_loss: 74.6812\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 51.9431 - val_loss: 461.2909\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 167.8549 - val_loss: 40.5811\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 68.5710 - val_loss: 75.7601\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 106.7650 - val_loss: 36.7960\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 38.3436 - val_loss: 35.4265\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 52.8644 - val_loss: 55.3768\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 62.2891 - val_loss: 63.3837\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 54.5422 - val_loss: 147.8086\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 88.8829 - val_loss: 49.0205\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 75.2888 - val_loss: 183.6736\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 87.3048 - val_loss: 85.2771\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 78.5079 - val_loss: 63.5303\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 58.2989 - val_loss: 47.2739\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 51.7765 - val_loss: 83.8593\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 70.9383 - val_loss: 44.7016\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 54.5816 - val_loss: 42.0043\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 64.1221 - val_loss: 33.5784\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 43.7142 - val_loss: 36.6092\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 37.2195 - val_loss: 34.4011\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 37.3425 - val_loss: 40.0105\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 48.2254 - val_loss: 31.4107\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 47.4584 - val_loss: 33.3945\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 66.9897 - val_loss: 46.5039\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 40.6032 - val_loss: 64.9884\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 49.6399 - val_loss: 48.5191\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 48.6579 - val_loss: 25.6194\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.2450 - val_loss: 27.7144\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.5613 - val_loss: 25.6169\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.1211 - val_loss: 28.4636\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.7068 - val_loss: 23.5231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a875b1ac0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default paramater of SGD  ---> learning_rate=0.01, momentum=0.0\n",
    "optimizer_sgd = SGD(learning_rate=0.01,momentum=0.9)\n",
    "model2 = Sequential()\n",
    "model2.add(BatchNormalization(input_shape=(13,)))\n",
    "model2.add(Dense(1))\n",
    "model2.compile(optimizer=optimizer_sgd, loss='mse')\n",
    "model2.fit(feature,price,epochs=50,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3178af0a-db1c-421f-9a24-377770160a86",
   "metadata": {},
   "source": [
    "- after changeing the learning rate and momentun of optimzer we can see that the loss is now decreasing gradually "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ebbcebb-5daa-4c53-bd6e-a78bab9b73fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 799us/step - loss: 47.7968\n",
      "47.796775817871094\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(feature,price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "958c8da1-b62c-4222-923e-41ad9ccabd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 745us/step - loss: 25.1958\n",
      "25.195837020874023\n"
     ]
    }
   ],
   "source": [
    "print(model2.evaluate(feature,price))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98dede0-5010-40cd-bc4c-5b3220ecc10b",
   "metadata": {},
   "source": [
    "- after comparing training and testing loss of model we can clearly observe that the loss of NN is totally depends on the learning rate and momentun\n",
    "- hence while training NN we should have to take care about the optimizer we are using because it helps the NN to updates the weights and move in a same direction if there is a batch who is saying to move in opposite direction due to bad data or outliers as per gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10118ea-784c-48f2-8ef9-be6e2f8b29f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
